{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%load_ext autoreload\n%autoreload 2cd \n%config InlineBackend.figure_format = 'retina'\n\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nimport numpy as np","metadata":{"execution":{"iopub.status.busy":"2022-05-02T03:17:31.013262Z","iopub.execute_input":"2022-05-02T03:17:31.013769Z","iopub.status.idle":"2022-05-02T03:17:31.040655Z","shell.execute_reply.started":"2022-05-02T03:17:31.013722Z","shell.execute_reply":"2022-05-02T03:17:31.039818Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lr = 0.001\nepochs = 10\nbatch_size = 2048\nhidden_units = 500\nmax_features = 15000\n_max_df = 0.11\n_min_df = 1","metadata":{"execution":{"iopub.status.busy":"2022-05-02T03:17:31.110325Z","iopub.execute_input":"2022-05-02T03:17:31.111133Z","iopub.status.idle":"2022-05-02T03:17:31.117822Z","shell.execute_reply.started":"2022-05-02T03:17:31.111085Z","shell.execute_reply":"2022-05-02T03:17:31.116856Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Preguntas teóricas:\n1) Qué relación hay entre el TF-IDF y el CountVectorizer?\nAmbos son medios de conversión de palabras a números para que una computadora pueda asignarles algún tipo de peso. Count Vectorizer se apoya en la frecuencia de aparición de las palabras, mientras que TF-IDF (Term Frequency - Inverse Document Frequency) usa una expresión más refinada que le da más peso a una palabra si aparece muchas veces en un mismo documento pero se lo reduce si aparece en muchos documentos distintos, ayudando a reducir la dimensionalidad de entrada al permitirnos filtrar términos menos importantes. La idea es que palabras que aparecen demasiadas veces o demasiado poco, tienen menor relevancia estadística.\n\n2) Explique el concepto de Bag Of Words\nEs un modelo que vectoriza un texto a partir de las palabras que aparecen en él, y la cantidad de veces que aparecen. No preserva orden, ya que sólo le importa la cantidad de ocurrencias (o multiplicidad).  \n\n\n3) Para validar sus resultados deberá utilizar siempre el método Hold-Out validation. Explíquelo y compárelo con K-Folding (investigar).\nHold out validation consiste en retener (o holdear) una parte del set de datos destinado al entrenamiento, la cual, una vez entrenado el modelo, se va a utilizar para corroborar el performance del mismo. K-folding es una idea similar, con la salvedad de repite el proceso múltiples veces y en cada iteración cambia el subconjunto de pruebas. K-folding es especialmente útil en los casos donde el set de muestras es limitado, aunque requiere más poder de cómputo.\n\n4) Explique la métrica utilizada en la competencia (Macro AUC-ROC). Investigue la métrica F1-score. Compárelas. \nAUC-ROC (Area under the curve - Receiver Operation Characteristic) es la composición de dos conceptos separados. En primer lugar, ROC es una métrica para la clasificación binaria, basada en comparar la tasa de verdaderos positivos contra falsos positivos. Se produce una curva al variar parámetros de nuestro modelo, en el cual al aumentar los verdaderos positivos, eventualmente también aumentan los falsos positivos. Un modelo bueno aumentará sus verdaderos positivos sin aumentar significativamente sus falsos positivos. La curva resultante se le aplica el AUC, Area Under Curve. Si el area debajo de la curva formada en el ROC es 1, el modelo es ideal e identifica correctamente todos los positivos sin incurrir en falsos positivos adicionales. Si no, igualmente se puede considerar funcional mientras el área sea mayor que 0.5, a partir de donde el modelo estaría prediciendo de forma prácticamente aleatoria. Un área menor a 0.5 implica que el modelo está adivinando de forma inversa a la que debería.","metadata":{}},{"cell_type":"markdown","source":"# Importo dataset","metadata":{}},{"cell_type":"code","source":"folder = './'\ntrain = pd.read_csv('../input/toxic-comments-challenge/train.csv')\ntest = pd.read_csv('../input/toxic-comments-challenge/test.csv')\nsubmission = pd.read_csv('../input/toxic-comments-challenge/sample_submission.csv')\n\nimport shutil\n\noriginal = r'/kaggle/input/porfavor/helper.py' #Esto es para evitar cargar los helpers a mano cada vez.\ntarget = r'/kaggle/working/helper.py'\nshutil.copyfile(original, target)\n\noriginal = r'/kaggle/input/porfavor/toxic_helper.py'\ntarget = r'/kaggle/working/toxic_helper.py'\nshutil.copyfile(original, target)\n\noriginal = r'/kaggle/input/porfavor/multiclass_helper.py'\ntarget = r'/kaggle/working/multiclass_helper.py'\nshutil.copyfile(original, target)\n\noriginal = r'/kaggle/input/porfavor/fnn_helper.py'\ntarget = r'/kaggle/working/fnn_helper.py'\nshutil.copyfile(original, target)","metadata":{"execution":{"iopub.status.busy":"2022-05-02T03:17:31.195755Z","iopub.execute_input":"2022-05-02T03:17:31.196295Z","iopub.status.idle":"2022-05-02T03:17:33.694999Z","shell.execute_reply.started":"2022-05-02T03:17:31.19626Z","shell.execute_reply":"2022-05-02T03:17:33.69401Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#train[:10] #Solo para ver contenido del archivo de train, cargado con pandas.\ntrain.head() #Muestra los datos de train que estoy usando, lo mismo que arriba pero con .head() de pandas.","metadata":{"execution":{"iopub.status.busy":"2022-05-02T03:17:33.696842Z","iopub.execute_input":"2022-05-02T03:17:33.697065Z","iopub.status.idle":"2022-05-02T03:17:33.712068Z","shell.execute_reply.started":"2022-05-02T03:17:33.697039Z","shell.execute_reply":"2022-05-02T03:17:33.711002Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.shape #Me devuelve el tamaño en columnas y filas del archivo.","metadata":{"execution":{"iopub.status.busy":"2022-05-02T03:17:33.713966Z","iopub.execute_input":"2022-05-02T03:17:33.714282Z","iopub.status.idle":"2022-05-02T03:17:33.728017Z","shell.execute_reply.started":"2022-05-02T03:17:33.71424Z","shell.execute_reply":"2022-05-02T03:17:33.727231Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"list_classes = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\ny = train[list_classes].values #Devuelve los valores de las columnas incluidas en list_classes\n#y[:10] #Hasta aca nada muy loco. Es funciones varias de Python y pandas.","metadata":{"execution":{"iopub.status.busy":"2022-05-02T03:17:33.730242Z","iopub.execute_input":"2022-05-02T03:17:33.730575Z","iopub.status.idle":"2022-05-02T03:17:33.742661Z","shell.execute_reply.started":"2022-05-02T03:17:33.730531Z","shell.execute_reply":"2022-05-02T03:17:33.741644Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Divido entre train y valid","metadata":{}},{"cell_type":"code","source":"X_train, X_valid, Y_train, Y_valid = train_test_split(train, y, test_size = 0.1) #Split arrays or matrices into random train and test subsets.\n\n#test_sizefloat or int, default=None\n#If float, should be between 0.0 and 1.0 and represent the proportion of the dataset to include in the test split. \n#If int, represents the absolute number of test samples. If None, the value is set to the complement of the train size. If train_size is also None, it will be set to 0.25.","metadata":{"execution":{"iopub.status.busy":"2022-05-02T03:17:33.744137Z","iopub.execute_input":"2022-05-02T03:17:33.744379Z","iopub.status.idle":"2022-05-02T03:17:33.79628Z","shell.execute_reply.started":"2022-05-02T03:17:33.744343Z","shell.execute_reply":"2022-05-02T03:17:33.795316Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Analisis rapido","metadata":{}},{"cell_type":"code","source":"toxic_ratio = (Y_train.sum(axis = 1) > 0).sum()/Y_train.shape[0] #Shape devuelve (filas, columnas). sum(axis = 1) colapsa las columnas en una sola sumando sus contenidos.\nprint(toxic_ratio) #Este código básicamente se fija cuales comentarios tienen algún tipo de toxicidad y luego calcula el porcentaje de comentarios tóxicos frente al total.","metadata":{"execution":{"iopub.status.busy":"2022-05-02T03:17:33.797681Z","iopub.execute_input":"2022-05-02T03:17:33.797897Z","iopub.status.idle":"2022-05-02T03:17:33.806895Z","shell.execute_reply.started":"2022-05-02T03:17:33.79787Z","shell.execute_reply":"2022-05-02T03:17:33.806083Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"0.96-toxic_ratio + toxic_ratio*0.873 # Ni idea.","metadata":{"execution":{"iopub.status.busy":"2022-05-02T03:17:33.808181Z","iopub.execute_input":"2022-05-02T03:17:33.808598Z","iopub.status.idle":"2022-05-02T03:17:33.822364Z","shell.execute_reply.started":"2022-05-02T03:17:33.808547Z","shell.execute_reply":"2022-05-02T03:17:33.821491Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train.shape #Puedo ver que de los 159k comentarios tomamos solo 143k para entrenar el modelo.","metadata":{"execution":{"iopub.status.busy":"2022-05-02T03:17:33.824054Z","iopub.execute_input":"2022-05-02T03:17:33.82457Z","iopub.status.idle":"2022-05-02T03:17:33.836207Z","shell.execute_reply.started":"2022-05-02T03:17:33.824522Z","shell.execute_reply":"2022-05-02T03:17:33.835443Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"raw_text_train = X_train[\"comment_text\"].str.lower() #Paso todo a lowercase, para independizar al analisis de las mayúsculas.\nraw_text_valid = X_valid[\"comment_text\"].str.lower()\nraw_text_test = test[\"comment_text\"].str.lower()","metadata":{"execution":{"iopub.status.busy":"2022-05-02T03:17:33.837818Z","iopub.execute_input":"2022-05-02T03:17:33.838505Z","iopub.status.idle":"2022-05-02T03:17:34.422185Z","shell.execute_reply.started":"2022-05-02T03:17:33.838458Z","shell.execute_reply":"2022-05-02T03:17:34.4212Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(raw_text_train[0:10]) # Recordar que train_test_split hace shuffle ","metadata":{"execution":{"iopub.status.busy":"2022-05-02T03:17:34.425681Z","iopub.execute_input":"2022-05-02T03:17:34.425924Z","iopub.status.idle":"2022-05-02T03:17:34.433885Z","shell.execute_reply.started":"2022-05-02T03:17:34.425895Z","shell.execute_reply":"2022-05-02T03:17:34.432811Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Y_train[:10]","metadata":{"execution":{"iopub.status.busy":"2022-05-02T03:17:34.435568Z","iopub.execute_input":"2022-05-02T03:17:34.435896Z","iopub.status.idle":"2022-05-02T03:17:34.449557Z","shell.execute_reply.started":"2022-05-02T03:17:34.435853Z","shell.execute_reply":"2022-05-02T03:17:34.448556Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Stemming o Lemmatizer","metadata":{}},{"cell_type":"markdown","source":"Stemming usa la raíz de la palabra para clasificarla, considerando a cualquier variación de una palabra como la misma palabra.\nLemmatizer utiliza el contexto de la palabra.\n\"Regular dictionaries are lists of lemmas, not stems\"\nProblema de stem: Dos palabras distintas pueden tener el mismo stem.\n","metadata":{}},{"cell_type":"code","source":"from nltk import word_tokenize          \nfrom nltk.stem import WordNetLemmatizer \nclass LemmaTokenizer(object): #Creo una clase lista para procesar con lemmatizer.\n    def __init__(self):\n        self.wnl = WordNetLemmatizer()\n    def __call__(self, doc):\n        return [self.wnl.lemmatize(t) for t in word_tokenize(doc)]\n    \nlemma = LemmaTokenizer()","metadata":{"execution":{"iopub.status.busy":"2022-05-02T03:17:34.451007Z","iopub.execute_input":"2022-05-02T03:17:34.451241Z","iopub.status.idle":"2022-05-02T03:17:34.461714Z","shell.execute_reply.started":"2022-05-02T03:17:34.451214Z","shell.execute_reply":"2022-05-02T03:17:34.460664Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from nltk.stem.porter import PorterStemmer\nimport re\ntoken_pattern=r\"(?u)\\b\\w\\w+\\b\"\ncompiled_reg_exp = re.compile(token_pattern)\ndef tokenize(text): #Defino una función para recuperar el stem de las palabras.\n    tokens = compiled_reg_exp.findall(text)\n    stems = []\n    for item in tokens:\n        if len(item)>100:\n            item = 'tooLongWord'\n        stems.append(PorterStemmer().stem(item))\n    return stems","metadata":{"execution":{"iopub.status.busy":"2022-05-02T03:17:34.462939Z","iopub.execute_input":"2022-05-02T03:17:34.463551Z","iopub.status.idle":"2022-05-02T03:17:34.47633Z","shell.execute_reply.started":"2022-05-02T03:17:34.463518Z","shell.execute_reply":"2022-05-02T03:17:34.47547Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Armo matriz de features","metadata":{}},{"cell_type":"markdown","source":"Features in a neural network are the variables or attributes in your data set. You usually pick a subset of variables that can be used as good predictors by your model. So in a neural network, the features would be the input layer, not the hidden layer nodes. The output is whatever variable (or variables) you're trying to predict.\n\n\nmax_dffloat or int, default=1.0\nWhen building the vocabulary ignore terms that have a document frequency strictly higher than the given threshold (corpus-specific stop words). If float in range [0.0, 1.0], the parameter represents a proportion of documents, integer absolute counts. This parameter is ignored if vocabulary is not None.\n\nmin_dffloat or int, default=1\nWhen building the vocabulary ignore terms that have a document frequency strictly lower than the given threshold. This value is also called cut-off in the literature. If float in range of [0.0, 1.0], the parameter represents a proportion of documents, integer absolute counts. This parameter is ignored if vocabulary is not None.\n","metadata":{}},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer #TfidfVectorizer - Transforms text to feature vectors that can be used as input to estimator.\n\n#max_features = 10000\n\ntfidf_vectorizer = TfidfVectorizer(max_df = _max_df, min_df = _min_df,\n                                   max_features=max_features,\n                                   #tokenizer=tokenize,\n                                   stop_words='english')\n\n%time tfidf_matrix_train = tfidf_vectorizer.fit_transform(raw_text_train) #Procesa la X_Train (raw text train) y lo transforma en una matriz esparsa ","metadata":{"execution":{"iopub.status.busy":"2022-05-02T03:17:34.47755Z","iopub.execute_input":"2022-05-02T03:17:34.477917Z","iopub.status.idle":"2022-05-02T03:17:45.543409Z","shell.execute_reply.started":"2022-05-02T03:17:34.477886Z","shell.execute_reply":"2022-05-02T03:17:45.542365Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Regarding tfidf_vectorizer.fit_transform: https://stackoverflow.com/questions/50906210/confused-with-the-return-result-of-tfidfvectorizer-fit-transform\n\nYou are printing a sparse matrix so the output looks different compared to printing a standard dense matrix. See below the main components:\n\nThe tuple represents: (document_id, token_id)\n\nThe value following the tuple represents the tf-idf score of a given token in a given document\n\nThe tuples that are not there have a tf-idf score of 0\n\nIf you want to find what token the token_id corresponds to, check the get_feature_names method.","metadata":{}},{"cell_type":"code","source":"%time tfidf_matrix_valid = tfidf_vectorizer.transform(raw_text_valid) #Hago lo mismo con la validación, pero con transform en lugar de fit_transform. ","metadata":{"execution":{"iopub.status.busy":"2022-05-02T03:17:45.544656Z","iopub.execute_input":"2022-05-02T03:17:45.544913Z","iopub.status.idle":"2022-05-02T03:17:46.767767Z","shell.execute_reply.started":"2022-05-02T03:17:45.544884Z","shell.execute_reply":"2022-05-02T03:17:46.766782Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%time tfidf_matrix_test = tfidf_vectorizer.transform(raw_text_test) #Voy a tener que preguntar cual es la diferencia.","metadata":{"execution":{"iopub.status.busy":"2022-05-02T03:17:46.769163Z","iopub.execute_input":"2022-05-02T03:17:46.769394Z","iopub.status.idle":"2022-05-02T03:17:57.380717Z","shell.execute_reply.started":"2022-05-02T03:17:46.769367Z","shell.execute_reply":"2022-05-02T03:17:57.379807Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Sparsity","metadata":{}},{"cell_type":"code","source":"sparsity = 1 - (tfidf_matrix_train>0).sum()/(tfidf_matrix_train.shape[0]*tfidf_matrix_train.shape[1]) #La cantidad de palabras que cumplen los criterios de maxdf y mindf dividido las palabras totales.\nprint(sparsity)","metadata":{"execution":{"iopub.status.busy":"2022-05-02T03:17:57.382268Z","iopub.execute_input":"2022-05-02T03:17:57.382537Z","iopub.status.idle":"2022-05-02T03:17:57.54651Z","shell.execute_reply.started":"2022-05-02T03:17:57.382496Z","shell.execute_reply":"2022-05-02T03:17:57.545608Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## TFIDF Results","metadata":{}},{"cell_type":"code","source":"tfidf_matrix_train.shape","metadata":{"execution":{"iopub.status.busy":"2022-05-02T03:17:57.548136Z","iopub.execute_input":"2022-05-02T03:17:57.548795Z","iopub.status.idle":"2022-05-02T03:17:57.556752Z","shell.execute_reply.started":"2022-05-02T03:17:57.548747Z","shell.execute_reply":"2022-05-02T03:17:57.556061Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"sin lemma\n- 177719 con 0.95, 1\n- 177712 con 0.11, 1\n","metadata":{}},{"cell_type":"code","source":"top_10 = np.argsort(tfidf_matrix_train.sum(axis=0))[0,::-1][0,:10].tolist()[0] #Lol?\nfeature_names = np.array(tfidf_vectorizer.get_feature_names()) #Devuelve el nombre de los features y los vectoriza, luego los hace arreglo?\nprint(feature_names[np.array(top_10)]) #Imprime las 10 palabras que más aparecen en los features.","metadata":{"execution":{"iopub.status.busy":"2022-05-02T03:17:57.557928Z","iopub.execute_input":"2022-05-02T03:17:57.558164Z","iopub.status.idle":"2022-05-02T03:17:57.606655Z","shell.execute_reply.started":"2022-05-02T03:17:57.558136Z","shell.execute_reply":"2022-05-02T03:17:57.606019Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Sin reducción de dimensionalidad","metadata":{}},{"cell_type":"code","source":"#dense_matrix_train = tfidf_matrix_train.todense()","metadata":{"execution":{"iopub.status.busy":"2022-05-02T03:17:57.607832Z","iopub.execute_input":"2022-05-02T03:17:57.608348Z","iopub.status.idle":"2022-05-02T03:17:57.61311Z","shell.execute_reply.started":"2022-05-02T03:17:57.608296Z","shell.execute_reply":"2022-05-02T03:17:57.612457Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#dense_matrix_train.shape, Y_train.shape","metadata":{"execution":{"iopub.status.busy":"2022-05-02T03:17:57.614127Z","iopub.execute_input":"2022-05-02T03:17:57.61494Z","iopub.status.idle":"2022-05-02T03:17:57.628986Z","shell.execute_reply.started":"2022-05-02T03:17:57.614905Z","shell.execute_reply":"2022-05-02T03:17:57.628071Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#dense_matrix_valid = tfidf_matrix_valid.todense()","metadata":{"execution":{"iopub.status.busy":"2022-05-02T03:17:57.630442Z","iopub.execute_input":"2022-05-02T03:17:57.631063Z","iopub.status.idle":"2022-05-02T03:17:57.645931Z","shell.execute_reply.started":"2022-05-02T03:17:57.63103Z","shell.execute_reply":"2022-05-02T03:17:57.644862Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Reducimos dimensionalidad","metadata":{}},{"cell_type":"code","source":"from sklearn.decomposition import TruncatedSVD","metadata":{"execution":{"iopub.status.busy":"2022-05-02T03:17:57.647125Z","iopub.execute_input":"2022-05-02T03:17:57.647346Z","iopub.status.idle":"2022-05-02T03:17:57.660702Z","shell.execute_reply.started":"2022-05-02T03:17:57.647319Z","shell.execute_reply":"2022-05-02T03:17:57.65988Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trunSVD = TruncatedSVD(n_components=300)\n%time dense_matrix_train = trunSVD.fit_transform(tfidf_matrix_train)","metadata":{"execution":{"iopub.status.busy":"2022-05-02T03:17:57.661952Z","iopub.execute_input":"2022-05-02T03:17:57.662321Z","iopub.status.idle":"2022-05-02T03:18:36.887383Z","shell.execute_reply.started":"2022-05-02T03:17:57.662277Z","shell.execute_reply":"2022-05-02T03:18:36.886451Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%time dense_matrix_valid = trunSVD.transform(tfidf_matrix_valid)","metadata":{"execution":{"iopub.status.busy":"2022-05-02T03:18:36.888698Z","iopub.execute_input":"2022-05-02T03:18:36.888938Z","iopub.status.idle":"2022-05-02T03:18:37.059959Z","shell.execute_reply.started":"2022-05-02T03:18:36.888909Z","shell.execute_reply":"2022-05-02T03:18:37.058942Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dense_matrix_train.shape, dense_matrix_valid.shape","metadata":{"execution":{"iopub.status.busy":"2022-05-02T03:18:37.061892Z","iopub.execute_input":"2022-05-02T03:18:37.062151Z","iopub.status.idle":"2022-05-02T03:18:37.070371Z","shell.execute_reply.started":"2022-05-02T03:18:37.06212Z","shell.execute_reply":"2022-05-02T03:18:37.069444Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%time dense_matrix_test = trunSVD.transform(tfidf_matrix_test)","metadata":{"execution":{"iopub.status.busy":"2022-05-02T03:18:37.072273Z","iopub.execute_input":"2022-05-02T03:18:37.07288Z","iopub.status.idle":"2022-05-02T03:18:38.608023Z","shell.execute_reply.started":"2022-05-02T03:18:37.072822Z","shell.execute_reply":"2022-05-02T03:18:38.607087Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Modelo de 1 capa densa","metadata":{}},{"cell_type":"code","source":"#!pip install toxic_helper\n!pip install detoxify\nfrom toxic_helper import auc","metadata":{"execution":{"iopub.status.busy":"2022-05-02T03:18:38.613244Z","iopub.execute_input":"2022-05-02T03:18:38.613702Z","iopub.status.idle":"2022-05-02T03:18:49.2552Z","shell.execute_reply.started":"2022-05-02T03:18:38.613652Z","shell.execute_reply":"2022-05-02T03:18:49.254157Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow import keras as keras\nfrom keras.models import Sequential\nfrom keras import optimizers\nfrom keras.layers.core import Dense, Activation\nfrom helper import PlotLosses\nfrom keras.callbacks import ModelCheckpoint\nfrom keras.initializers import RandomNormal\nfrom keras import regularizers\nfrom keras import initializers","metadata":{"execution":{"iopub.status.busy":"2022-05-02T03:18:49.258032Z","iopub.execute_input":"2022-05-02T03:18:49.258409Z","iopub.status.idle":"2022-05-02T03:18:49.266187Z","shell.execute_reply.started":"2022-05-02T03:18:49.258367Z","shell.execute_reply":"2022-05-02T03:18:49.265318Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"default_initializer = initializers.normal(mean=0, stddev=0.001) #Defino una gaussiana por algún motivo u otro.\n# default_initializer = 'zeros'","metadata":{"execution":{"iopub.status.busy":"2022-05-02T03:18:49.267557Z","iopub.execute_input":"2022-05-02T03:18:49.2678Z","iopub.status.idle":"2022-05-02T03:18:49.282818Z","shell.execute_reply.started":"2022-05-02T03:18:49.267771Z","shell.execute_reply":"2022-05-02T03:18:49.281918Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_features = dense_matrix_train.shape[1]  #Cantidad de features de entrada\noutput_size = Y_train.shape[1] #Dimensión de la salida\n#hidden_units = 100\nlambd = 0 #0.001\nmodel_sig_nn = Sequential() #Es el modelo. Le puedo agregar las capas que quiera.\nmodel_sig_nn.add(Dense(hidden_units,\n                       input_dim=input_features, \n                       kernel_regularizer=regularizers.l2(lambd), \n                       kernel_initializer=default_initializer,\n                       name=\"Capa_Oculta_1\"))  # https://keras.io/api/layers/core_layers/dense/\nmodel_sig_nn.add(Activation('sigmoid')) #Capas con activación sigmoidea, 50 neuronas, input_features entradas, y tengo que ver qué onda los regularizers y el initializer.\nmodel_sig_nn.add(Dense(hidden_units,\n                       input_dim=input_features, \n                       kernel_regularizer=regularizers.l2(lambd), \n                       kernel_initializer=default_initializer,\n                       name=\"Capa_Oculta_2\"))\nmodel_sig_nn.add(Activation('sigmoid'))\nmodel_sig_nn.add(Dense(output_size,\n                       kernel_regularizer=regularizers.l2(lambd), \n                       kernel_initializer=default_initializer,\n                       name=\"Capa_Salida\"))\nmodel_sig_nn.add(Activation('sigmoid', name=\"output\")) \nmodel_sig_nn.summary()\n\n\n#lr = 0.1\n#batch_size = 64\n#epochs = 10\n\n#selectedOptimizer = keras.optimizers.SGD(learning_rate=lr)\nselectedOptimizer = keras.optimizers.Adam(lr=lr)\n\nmodel_sig_nn.compile(loss = 'binary_crossentropy', optimizer=selectedOptimizer, \n                     metrics=['accuracy']) #auc","metadata":{"execution":{"iopub.status.busy":"2022-05-02T03:18:49.284318Z","iopub.execute_input":"2022-05-02T03:18:49.28459Z","iopub.status.idle":"2022-05-02T03:18:49.361334Z","shell.execute_reply.started":"2022-05-02T03:18:49.28456Z","shell.execute_reply":"2022-05-02T03:18:49.360697Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_sig_nn.evaluate(dense_matrix_valid, Y_valid)","metadata":{"execution":{"iopub.status.busy":"2022-05-02T03:18:49.362565Z","iopub.execute_input":"2022-05-02T03:18:49.362771Z","iopub.status.idle":"2022-05-02T03:18:50.813457Z","shell.execute_reply.started":"2022-05-02T03:18:49.362745Z","shell.execute_reply":"2022-05-02T03:18:50.812583Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.callbacks import ModelCheckpoint\ncheckpointer = ModelCheckpoint(filepath='/kaggle/working/basic_model_best.hdf5', verbose=1, save_best_only=True) #verbose=1 will show you an animated progress bar\n\nplot_losses = PlotLosses(plot_interval=1, \n                         evaluate_interval=5, \n                         x_val=dense_matrix_valid, \n                         y_val_categorical=Y_valid)\nhistory = model_sig_nn.fit(dense_matrix_train, \n          Y_train, \n          batch_size = batch_size,\n          epochs=epochs, \n          verbose=1, \n          validation_data=(dense_matrix_valid, Y_valid), \n          callbacks=[plot_losses, checkpointer],\n         )","metadata":{"execution":{"iopub.status.busy":"2022-05-02T03:18:50.814669Z","iopub.execute_input":"2022-05-02T03:18:50.814908Z","iopub.status.idle":"2022-05-02T03:22:06.788556Z","shell.execute_reply.started":"2022-05-02T03:18:50.814879Z","shell.execute_reply":"2022-05-02T03:22:06.787201Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Evaluo valid","metadata":{}},{"cell_type":"code","source":"model_sig_nn.load_weights('/kaggle/working/basic_model_best.hdf5')","metadata":{"execution":{"iopub.status.busy":"2022-05-02T03:22:06.790091Z","iopub.execute_input":"2022-05-02T03:22:06.790307Z","iopub.status.idle":"2022-05-02T03:22:06.806588Z","shell.execute_reply.started":"2022-05-02T03:22:06.790281Z","shell.execute_reply":"2022-05-02T03:22:06.805388Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tfidf_matrix_valid.shape, Y_valid.shape","metadata":{"execution":{"iopub.status.busy":"2022-05-02T03:22:06.808261Z","iopub.execute_input":"2022-05-02T03:22:06.808609Z","iopub.status.idle":"2022-05-02T03:22:06.81776Z","shell.execute_reply.started":"2022-05-02T03:22:06.808566Z","shell.execute_reply":"2022-05-02T03:22:06.816738Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred_valid = model_sig_nn.predict(dense_matrix_valid, verbose = 1)\npred_train = model_sig_nn.predict(dense_matrix_train, verbose = 1)\npred_test = model_sig_nn.predict(dense_matrix_test, verbose = 1)","metadata":{"execution":{"iopub.status.busy":"2022-05-02T03:22:06.819306Z","iopub.execute_input":"2022-05-02T03:22:06.819667Z","iopub.status.idle":"2022-05-02T03:22:26.716066Z","shell.execute_reply.started":"2022-05-02T03:22:06.819621Z","shell.execute_reply":"2022-05-02T03:22:26.715123Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_sig_nn.evaluate(dense_matrix_valid, Y_valid)","metadata":{"execution":{"iopub.status.busy":"2022-05-02T03:22:26.717298Z","iopub.execute_input":"2022-05-02T03:22:26.717556Z","iopub.status.idle":"2022-05-02T03:22:27.958289Z","shell.execute_reply.started":"2022-05-02T03:22:26.717526Z","shell.execute_reply":"2022-05-02T03:22:27.957453Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"[0.073181636426992352, 0.97782721309109666]","metadata":{}},{"cell_type":"markdown","source":"# ROC Curve","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import roc_curve, auc\nfrom scipy import interp\nfrom itertools import cycle\n\nprint(roc_auc_score(Y_train, pred_train, average='macro'))\nprint(roc_auc_score(Y_valid, pred_valid, average='macro'))","metadata":{"execution":{"iopub.status.busy":"2022-05-02T03:22:27.959509Z","iopub.execute_input":"2022-05-02T03:22:27.959719Z","iopub.status.idle":"2022-05-02T03:22:28.249469Z","shell.execute_reply.started":"2022-05-02T03:22:27.959693Z","shell.execute_reply":"2022-05-02T03:22:28.248395Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"0.930758815168  \n0.920441587397","metadata":{}},{"cell_type":"code","source":"fpr = dict()\ntpr = dict()\nroc_auc = dict()\nn_classes = Y_valid.shape[1]\nfor i in range(n_classes):\n    fpr[i], tpr[i], _ = roc_curve(Y_valid[:, i], pred_valid[:, i])\n    roc_auc[i] = auc(fpr[i], tpr[i])\n    \nfpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(Y_valid.ravel(), pred_valid.ravel())\nroc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])","metadata":{"execution":{"iopub.status.busy":"2022-05-02T03:22:28.251647Z","iopub.execute_input":"2022-05-02T03:22:28.251977Z","iopub.status.idle":"2022-05-02T03:22:28.306639Z","shell.execute_reply.started":"2022-05-02T03:22:28.251932Z","shell.execute_reply":"2022-05-02T03:22:28.30568Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from matplotlib import pyplot as plt\n# Compute macro-average ROC curve and ROC area\nlw = 2\n# First aggregate all false positive rates\nall_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n\n# Then interpolate all ROC curves at this points\nmean_tpr = np.zeros_like(all_fpr)\nfor i in range(n_classes):\n    mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n\n# Finally average it and compute AUC\nmean_tpr /= n_classes\n\nfpr[\"macro\"] = all_fpr\ntpr[\"macro\"] = mean_tpr\nroc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n\n# Plot all ROC curves\nplt.figure()\nplt.plot(fpr[\"micro\"], tpr[\"micro\"],\n         label='micro-average ROC curve (area = {0:0.2f})'\n               ''.format(roc_auc[\"micro\"]),\n         color='deeppink', linestyle=':', linewidth=4)\n\nplt.plot(fpr[\"macro\"], tpr[\"macro\"],\n         label='macro-average ROC curve (area = {0:0.2f})'\n               ''.format(roc_auc[\"macro\"]),\n         color='navy', linestyle=':', linewidth=4)\n\ncolors = cycle(['aqua', 'darkorange', 'cornflowerblue'])\nfor i, color in zip(range(n_classes), colors):\n    plt.plot(fpr[i], tpr[i], color=color, lw=lw,\n             label='ROC curve of class {0} (area = {1:0.2f})'\n             ''.format(i, roc_auc[i]))\n\nplt.plot([0, 1], [0, 1], 'k--', lw=lw)\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Some extension of Receiver operating characteristic to multi-class')\nplt.legend(loc=\"lower right\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-02T03:22:28.307929Z","iopub.execute_input":"2022-05-02T03:22:28.308172Z","iopub.status.idle":"2022-05-02T03:22:28.659555Z","shell.execute_reply.started":"2022-05-02T03:22:28.308137Z","shell.execute_reply":"2022-05-02T03:22:28.658474Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"http://scikit-learn.org/stable/auto_examples/model_selection/plot_roc.html","metadata":{}},{"cell_type":"markdown","source":"**True Positive Rate**:   \nThe number of times your system was able to classify the positives as positives. \n\nTrue positive rate = Correctly Classified Positives/(Correctly Classified as Positives+ Falsely Classified as Negatives)\n\n**False Positive Rate**:  \nThe number of times your system classified a negative as a positive divided by the total  actual negative instances.\n\n\nFalse positive rate = Incorrectly Classified as Positives/(Incorrectly Classified as Positives+ Correctly classified as Negatives )","metadata":{}},{"cell_type":"markdown","source":"https://en.wikipedia.org/wiki/Receiver_operating_characteristic","metadata":{}},{"cell_type":"markdown","source":"https://datascience.stackexchange.com/questions/15989/micro-average-vs-macro-average-performance-in-a-multiclass-classification-settin/16001\n\nMacro-average: Calcula el score de cada clase y luego promedia  \nMicro-average: Suma y luego calcula el score\n\nMicro-average se considera mejor cuando hay desbalce en las clases","metadata":{}},{"cell_type":"markdown","source":"# Interpretación","metadata":{}},{"cell_type":"markdown","source":"- toxic\n- severe_toxic\n- obscene\n- threat\n- insult\n- identity_hate","metadata":{}},{"cell_type":"code","source":"(model_sig_nn.get_weights()[0]).shape","metadata":{"execution":{"iopub.status.busy":"2022-05-02T03:22:28.660992Z","iopub.execute_input":"2022-05-02T03:22:28.661216Z","iopub.status.idle":"2022-05-02T03:22:28.669553Z","shell.execute_reply.started":"2022-05-02T03:22:28.661188Z","shell.execute_reply":"2022-05-02T03:22:28.668748Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"salida = 2\nsorted_indexes = np.argsort(model_sig_nn.get_weights()[0][:,salida])[::-1]\nnp.array(tfidf_vectorizer.get_feature_names())[sorted_indexes][:20]","metadata":{"execution":{"iopub.status.busy":"2022-05-02T03:22:28.670943Z","iopub.execute_input":"2022-05-02T03:22:28.67116Z","iopub.status.idle":"2022-05-02T03:22:28.715435Z","shell.execute_reply.started":"2022-05-02T03:22:28.671134Z","shell.execute_reply":"2022-05-02T03:22:28.714549Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Predict for test","metadata":{}},{"cell_type":"code","source":"tfidf_matrix_test = tfidf_vectorizer.transform(raw_text_test)","metadata":{"execution":{"iopub.status.busy":"2022-05-02T03:22:28.716667Z","iopub.execute_input":"2022-05-02T03:22:28.717268Z","iopub.status.idle":"2022-05-02T03:22:39.777675Z","shell.execute_reply.started":"2022-05-02T03:22:28.717235Z","shell.execute_reply":"2022-05-02T03:22:39.776758Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#dense_matrix_test = tfidf_matrix_test.todense()","metadata":{"execution":{"iopub.status.busy":"2022-05-02T03:22:39.779026Z","iopub.execute_input":"2022-05-02T03:22:39.779282Z","iopub.status.idle":"2022-05-02T03:22:39.784762Z","shell.execute_reply.started":"2022-05-02T03:22:39.77925Z","shell.execute_reply":"2022-05-02T03:22:39.783715Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred = model_sig_nn.predict(dense_matrix_test, verbose=1)","metadata":{"execution":{"iopub.status.busy":"2022-05-02T03:22:39.786042Z","iopub.execute_input":"2022-05-02T03:22:39.786291Z","iopub.status.idle":"2022-05-02T03:22:49.11533Z","shell.execute_reply.started":"2022-05-02T03:22:39.78626Z","shell.execute_reply":"2022-05-02T03:22:49.114217Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred.shape","metadata":{"execution":{"iopub.status.busy":"2022-05-02T03:22:49.116687Z","iopub.execute_input":"2022-05-02T03:22:49.116944Z","iopub.status.idle":"2022-05-02T03:22:49.124274Z","shell.execute_reply.started":"2022-05-02T03:22:49.116913Z","shell.execute_reply":"2022-05-02T03:22:49.12338Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"1*(pred[0:10]>0.5)","metadata":{"execution":{"iopub.status.busy":"2022-05-02T03:22:49.127661Z","iopub.execute_input":"2022-05-02T03:22:49.127917Z","iopub.status.idle":"2022-05-02T03:22:49.139488Z","shell.execute_reply.started":"2022-05-02T03:22:49.127887Z","shell.execute_reply":"2022-05-02T03:22:49.13857Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission[list_classes] = pred_test\nsubmission.to_csv(\"submission_TSVD_300.csv\", index = False)","metadata":{"execution":{"iopub.status.busy":"2022-05-02T03:22:49.140937Z","iopub.execute_input":"2022-05-02T03:22:49.141484Z","iopub.status.idle":"2022-05-02T03:22:50.685244Z","shell.execute_reply.started":"2022-05-02T03:22:49.141437Z","shell.execute_reply":"2022-05-02T03:22:50.6845Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Submit1 ROC AUC en valid = 0.731196488262  \nSubmit2 ROC AUC en valid = 0.963410980044  \nSubmit3 ROC AUC en valid = 0.974042855266","metadata":{}},{"cell_type":"code","source":"# ~/.local/bin/kaggle competitions submit -c jigsaw-toxic-comment-classification-challenge -f submission_early_stop_2_epochs.csv -m \"Early stop 2 epochs\"","metadata":{"execution":{"iopub.status.busy":"2022-05-02T03:22:50.686392Z","iopub.execute_input":"2022-05-02T03:22:50.686781Z","iopub.status.idle":"2022-05-02T03:22:50.691266Z","shell.execute_reply.started":"2022-05-02T03:22:50.68675Z","shell.execute_reply":"2022-05-02T03:22:50.690394Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}